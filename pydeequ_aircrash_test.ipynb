{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzHDE6ilToTMXIVwWblQlI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simerjit/pydeequ/blob/main/pydeequ_aircrash_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "T7WlTDrp4HEl"
      },
      "outputs": [],
      "source": [
        "# 1. Installs the required Java version for Spark.\n",
        "# 2. Download a specific version of Apache Spark (version 3.2.0) that's pre-built for compatibility with Hadoop 2.7\n",
        "# 3. Extract the contents of the downloaded Apache Spark tarball.\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall pyspark==3.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XklUSGOK4fR0",
        "outputId": "83e16139-e3fb-4a02-8d44-9f8f40083b8d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping pyspark as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up environmental variables for pyspark.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop2.7\"\n",
        "os.environ[\"SPARK_VERSION\"] = \"3.2\""
      ],
      "metadata": {
        "id": "swtQhOJU5gnS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pydeequ\n",
        "!pip install pydeequ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnro4enj4gq8",
        "outputId": "ada4a1bd-2e69-40b1-f3c9-5f476b4ea779"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydeequ in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from pydeequ) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from pydeequ) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23.0->pydeequ) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a Spark session integrated with the PyDeequ library for data quality checks\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import concat_ws\n",
        "import pydeequ\n",
        "\n",
        "spark = (SparkSession\n",
        "         .builder\n",
        "         .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
        "         .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
        "         .getOrCreate())\n"
      ],
      "metadata": {
        "id": "0VHXOLVF4sKJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading air crashes dataset\n",
        "df = spark.read.csv('/content/aircrashes.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "r06jKLuE4w-R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Year\", col(\"Year\").cast(\"int\"))\n",
        "df = df.withColumn(\"Date\", concat_ws(\"-\", \"Day\", \"Month\", \"Year\"))"
      ],
      "metadata": {
        "id": "F11xUKEu4zMQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing space in column names with \"_\" and removing characters like \"(\", \")\", \"/\".\n",
        "for col in df.columns:\n",
        "    new_col = col.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\")\n",
        "    df = df.withColumnRenamed(col, new_col)"
      ],
      "metadata": {
        "id": "0hC5-NoA41Hn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vImVzMXa5Tdw",
        "outputId": "b874ddeb-fb11-46bb-f034-6b5d29e27442"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+---------+---+--------------+---------------------+--------------------+--------------------+--------------------+-------------+---------------------+-------------+-----------------+\n",
            "|Year|Quarter|    Month|Day|Country_Region|Aircraft_Manufacturer|            Aircraft|            Location|            Operator|Sum_of_Ground|Sum_of_Fatalities_air|Sum_of_Aboard|             Date|\n",
            "+----+-------+---------+---+--------------+---------------------+--------------------+--------------------+--------------------+-------------+---------------------+-------------+-----------------+\n",
            "|1908|  Qtr 3|September| 17|      Virginia|         Wright Flyer|   Wright Flyer III?|  Fort Myer Virginia|Army U.S. - Military|            0|                    1|            2|17-September-1908|\n",
            "|1909|  Qtr 3|September|  7|       France?|               Wright|   Wright ByplaneSC1|Juvisy-sur-Orge F...|                 N/A|            0|                    1|            1| 7-September-1909|\n",
            "|1912|  Qtr 3|     July| 12|           New|           Dirigible?|          Dirigible?|   Atlantic City New|Navy U.S. - Jerse...|            0|                    5|            5|     12-July-1912|\n",
            "|1913|  Qtr 3|   August|  6|       British|              Curtiss|   Curtiss seaplane?|    Victoria British|Canada          C...|            0|                    1|            1|    6-August-1913|\n",
            "|1913|  Qtr 3|September|  9|           N/A|             Zeppelin|Zeppelin L 1 (air...|Over the North Se...|                 N/A|            0|                   14|           20| 9-September-1913|\n",
            "|1913|  Qtr 4|  October| 17|       Germany|             Zeppelin|Zeppelin L 2 (air...|Near Johannisthal...|Navy German - Mil...|            0|                   28|           28|  17-October-1913|\n",
            "|1915|  Qtr 1|    March|  5|       Belgium|             Zeppelin|Zeppelin L 8 (air...|      Tienen Belgium|Navy German - Mil...|            0|                   17|           41|     5-March-1915|\n",
            "|1915|  Qtr 3|September|  3|       Germany|             Zeppelin|Zeppelin L 10 (ai...|Off Cuxhaven Germany|Navy German - Mil...|            0|                   19|           19| 3-September-1915|\n",
            "|1916|  Qtr 3|     July| 28|      Bulgeria|              Schutte|     Schutte  Lanz S|Near Jambol Bulgeria|Army German - Mil...|            0|                   20|           20|     28-July-1916|\n",
            "|1916|  Qtr 3|September| 24|       England|             Zeppelin|Zeppelin L 32 (ai...|  Billericay England|Navy German - Mil...|            0|                   22|           22|24-September-1916|\n",
            "|1916|  Qtr 4|  October|  1|       England|             Zeppelin|Zeppelin L 31 (ai...| Potters Bar England|Navy German - Mil...|            0|                   19|           19|   1-October-1916|\n",
            "|1916|  Qtr 4| November| 21|       Germany|       Super Zeppelin|Super Zeppelin (a...|       Mainz Germany|Army German - Mil...|            0|                   27|           28| 21-November-1916|\n",
            "|1916|  Qtr 4| November| 28|       England|             Zeppelin|Zeppelin L 34 (ai...|Off West Hartlepo...|Navy German - Mil...|            0|                   20|           20| 28-November-1916|\n",
            "|1917|  Qtr 1|    March|  4|       Belgium|             Airship?|            Airship?|   Near Gent Belgium|Army German - Mil...|            0|                   20|           20|     4-March-1917|\n",
            "|1917|  Qtr 1|    March| 30|           N/A|              Schutte|     Schutte  Lanz S|Off Northern Germ...|                 N/A|            0|                   23|           23|    30-March-1917|\n",
            "|1917|  Qtr 2|      May| 14|         North|             Zeppelin|Zeppelin L 22 (ai...|Near Texel Island...|Navy German - Sea...|            0|                   21|           21|      14-May-1917|\n",
            "|1917|  Qtr 2|     June| 14|         North|             Zeppelin|Zeppelin L 43 (ai...|Off Vlieland Isla...|Navy German - Sea...|            0|                   24|           24|     14-June-1917|\n",
            "|1917|  Qtr 2|     June| 17|      England?|              Zepplin|Zepplin L 48 (air...|Near Yarmouth Eng...|                 N/A|            0|                   14|           16|     17-June-1917|\n",
            "|1917|  Qtr 3|   August| 21|           N/A|             Zeppelin|Zeppelin L 23 (ai...|Off western Denma...|                 N/A|            0|                   18|           18|   21-August-1917|\n",
            "|1917|  Qtr 4|  October| 20|        France|             Zeppelin|Zeppelin L 44 (ai...|Near Luneville Fr...|Navy German - Mil...|            0|                   18|           18|  20-October-1917|\n",
            "+----+-------+---------+---+--------------+---------------------+--------------------+--------------------+--------------------+-------------+---------------------+-------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics Computation**"
      ],
      "metadata": {
        "id": "dOJ17dki5IDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.analyzers import AnalysisRunner, AnalyzerContext, ApproxCountDistinct, Completeness, Compliance, Mean, Size, Correlation\n",
        "\n",
        "# Analyzing the 'Year' column\n",
        "# To see if the number of fatalities has decreased over the years, possibly due to advancements in aviation technology and safety measures.\n",
        "analysisResult = AnalysisRunner(spark) \\\n",
        "                  .onData(df) \\\n",
        "                  .addAnalyzer(Size()) \\\n",
        "                  .addAnalyzer(Completeness(\"Year\")) \\\n",
        "                  .addAnalyzer(ApproxCountDistinct(\"Year\")) \\\n",
        "                  .addAnalyzer(Mean(\"Year\")) \\\n",
        "                  .addAnalyzer(Compliance(\"Year\", \"Year > 1900\")) \\\n",
        "                  .addAnalyzer(Correlation(\"Year\", \"Sum_of_Fatalities_air\")) \\\n",
        "                  .run()\n",
        "\n",
        "# To retrieve the analysis results\n",
        "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
        "analysisResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg5tFATu5Jjn",
        "outputId": "753bd287-504e-4cd9-852f-feaf5ee53ae8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------------+-------------------+-------------------+\n",
            "|entity     |instance                  |name               |value              |\n",
            "+-----------+--------------------------+-------------------+-------------------+\n",
            "|Column     |Year                      |Compliance         |0.9956452889944576 |\n",
            "|Column     |Year                      |Completeness       |0.9956452889944576 |\n",
            "|Column     |Year                      |ApproxCountDistinct|113.0              |\n",
            "|Column     |Year                      |Mean               |1970.938369781312  |\n",
            "|Dataset    |*                         |Size               |5052.0             |\n",
            "|Mutlicolumn|Year,Sum_of_Fatalities_air|Correlation        |0.16161932596456652|\n",
            "+-----------+--------------------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run a profile of the dataset**"
      ],
      "metadata": {
        "id": "4PZU5ghA7h4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.profiles import ColumnProfilerRunner\n",
        "result = ColumnProfilerRunner(spark) \\\n",
        "                .onData(df) \\\n",
        "                .run()\n",
        "for col, profile in result.profiles.items():\n",
        "       print(f'Column \\'{col}\\'')\n",
        "       print('\\t',f'completeness: {profile.completeness}')\n",
        "       print('\\t',f'approximate number of distinct values: {profile.approximateNumDistinctValues}')\n",
        "       print('\\t',f'datatype: {profile.dataType}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81seEywj7jJy",
        "outputId": "52751f68-d8f7-493b-ef9e-e9f12fa7203a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Aircraft_Manufacturer'\n",
            "\t completeness: 0.996437054631829\n",
            "\t approximate number of distinct values: 634\n",
            "\t datatype: String\n",
            "Column 'Location'\n",
            "\t completeness: 0.9928741092636579\n",
            "\t approximate number of distinct values: 4092\n",
            "\t datatype: String\n",
            "Column 'Sum_of_Aboard'\n",
            "\t completeness: 0.9926761678543151\n",
            "\t approximate number of distinct values: 252\n",
            "\t datatype: Integral\n",
            "Column 'Operator'\n",
            "\t completeness: 0.9926761678543151\n",
            "\t approximate number of distinct values: 2655\n",
            "\t datatype: String\n",
            "Column 'Month'\n",
            "\t completeness: 0.9996041171813144\n",
            "\t approximate number of distinct values: 25\n",
            "\t datatype: String\n",
            "Column 'Sum_of_Fatalities_air'\n",
            "\t completeness: 0.9926761678543151\n",
            "\t approximate number of distinct values: 192\n",
            "\t datatype: Integral\n",
            "Column 'Quarter'\n",
            "\t completeness: 1.0\n",
            "\t approximate number of distinct values: 26\n",
            "\t datatype: String\n",
            "Column 'Year'\n",
            "\t completeness: 0.9956452889944576\n",
            "\t approximate number of distinct values: 113\n",
            "\t datatype: Integral\n",
            "Column 'Day'\n",
            "\t completeness: 0.9994061757719715\n",
            "\t approximate number of distinct values: 37\n",
            "\t datatype: String\n",
            "Column 'Sum_of_Ground'\n",
            "\t completeness: 0.9926761678543151\n",
            "\t approximate number of distinct values: 49\n",
            "\t datatype: Integral\n",
            "Column 'Country_Region'\n",
            "\t completeness: 0.9908946951702297\n",
            "\t approximate number of distinct values: 535\n",
            "\t datatype: String\n",
            "Column 'Date'\n",
            "\t completeness: 1.0\n",
            "\t approximate number of distinct values: 4906\n",
            "\t datatype: String\n",
            "Column 'Aircraft'\n",
            "\t completeness: 0.9944576405384006\n",
            "\t approximate number of distinct values: 3463\n",
            "\t datatype: String\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Constraint Verification**"
      ],
      "metadata": {
        "id": "rr5YTZWo7pNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "\n",
        "# Define the check\n",
        "check = Check(spark, CheckLevel.Warning, \"Air Crash Data Check\")\n",
        "\n",
        "# Run the verification\n",
        "checkResult = VerificationSuite(spark) \\\n",
        "    .onData(df) \\\n",
        "    .addCheck(\n",
        "        check.hasSize(lambda x: x >= 5000) \\\n",
        "        .isComplete(\"Year\") \\\n",
        "        .isComplete(\"Aircraft_Manufacturer\") \\\n",
        "        .isNonNegative(\"Sum_of_Fatalities_air\") \\\n",
        "        .isNonNegative(\"Year\")) \\\n",
        "    .run()\n",
        "\n",
        "# Convert the results to a DataFrame and show\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpSK4Fzp7qsO",
        "outputId": "e3b39459-1d6e-43a4-9272-8d8bedf19734"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Callback server started!\n",
            "+--------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------------------------------------------+\n",
            "|check               |check_level|check_status|constraint                                                                                                                                    |constraint_status|constraint_message                                                 |\n",
            "+--------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------------------------------------------+\n",
            "|Air Crash Data Check|Warning    |Warning     |SizeConstraint(Size(None))                                                                                                                    |Success          |                                                                   |\n",
            "|Air Crash Data Check|Warning    |Warning     |CompletenessConstraint(Completeness(Year,None))                                                                                               |Failure          |Value: 0.9956452889944576 does not meet the constraint requirement!|\n",
            "|Air Crash Data Check|Warning    |Warning     |CompletenessConstraint(Completeness(Aircraft_Manufacturer,None))                                                                              |Failure          |Value: 0.996437054631829 does not meet the constraint requirement! |\n",
            "|Air Crash Data Check|Warning    |Warning     |ComplianceConstraint(Compliance(Sum_of_Fatalities_air is non-negative,COALESCE(CAST(Sum_of_Fatalities_air AS DECIMAL(20,10)), 0.0) >= 0,None))|Success          |                                                                   |\n",
            "|Air Crash Data Check|Warning    |Warning     |ComplianceConstraint(Compliance(Year is non-negative,COALESCE(CAST(Year AS DECIMAL(20,10)), 0.0) >= 0,None))                                  |Success          |                                                                   |\n",
            "+--------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Automated constraint suggestion**"
      ],
      "metadata": {
        "id": "Ppd_kF-I7vPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.suggestions import *\n",
        "\n",
        "suggestionResult = ConstraintSuggestionRunner(spark) \\\n",
        "             .onData(df) \\\n",
        "             .addConstraintRule(DEFAULT()) \\\n",
        "             .run()\n",
        "\n",
        "for sugg in suggestionResult['constraint_suggestions']:\n",
        "       print(f\"Constraint suggestion for \\'{sugg['column_name']}\\': {sugg['description']}\")\n",
        "       print(f\"The corresponding Python code is: {sugg['code_for_constraint']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "049jp1Rp7wzt",
        "outputId": "6ccca124-b397-42c3-e936-9205e3664c0f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constraint suggestion for 'Aircraft_Manufacturer': 'Aircraft_Manufacturer' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Aircraft_Manufacturer\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Location': 'Location' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Location\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Sum_of_Aboard': 'Sum_of_Aboard' has no negative values\n",
            "The corresponding Python code is: .isNonNegative(\"Sum_of_Aboard\")\n",
            "\n",
            "Constraint suggestion for 'Sum_of_Aboard': 'Sum_of_Aboard' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Sum_of_Aboard\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Operator': 'Operator' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Operator\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Month': 'Month' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Month\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Sum_of_Fatalities_air': 'Sum_of_Fatalities_air' has no negative values\n",
            "The corresponding Python code is: .isNonNegative(\"Sum_of_Fatalities_air\")\n",
            "\n",
            "Constraint suggestion for 'Sum_of_Fatalities_air': 'Sum_of_Fatalities_air' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Sum_of_Fatalities_air\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Quarter': 'Quarter' is not null\n",
            "The corresponding Python code is: .isComplete(\"Quarter\")\n",
            "\n",
            "Constraint suggestion for 'Year': 'Year' has value range '1946', '1989', '1947', '1962', '1948', '1972', '1945', '1951', '1994', '1970', '1950', '1953', '1960', '1969', '1958', '1991', '1996', '1949', '1992', '1959', '1957', '1952', '1968', '1973', '1963', '1988', '1965', '2000', '1977', '1967', '1999', '2003', '1990', '1995', '1954', '1966', '1979', '1961', '1998', '1964', '1974', '2001', '1971', '1976', '1955', '1944', '1938', '1985', '1993', '1997', '2002', '1987', '1982', '1956', '2008', '1975', '1986', '1978', '1981', '1936', '1984', '1983', '2009', '2004', '2005', '1980', '1943', '2007', '1935', '2010', '1929', '2006', '1942', '1937', '2011', '1928', '1931', '1934', '1939', '1933', '1932', '1930', '1941', '2012', '1940', '2013', '2016', '2014', '1927', '2018', '2015', '1920', '2017', '1926', '1922', '1923', '2019', '1921', '1925', '2021', '1919', '2020', '1924', '1917', '2022', '1916', '1918', '1913', '1915', '2023', '1909', '1912', '1908'\n",
            "The corresponding Python code is: .isContainedIn(\"Year\", [\"1946\", \"1989\", \"1947\", \"1962\", \"1948\", \"1972\", \"1945\", \"1951\", \"1994\", \"1970\", \"1950\", \"1953\", \"1960\", \"1969\", \"1958\", \"1991\", \"1996\", \"1949\", \"1992\", \"1959\", \"1957\", \"1952\", \"1968\", \"1973\", \"1963\", \"1988\", \"1965\", \"2000\", \"1977\", \"1967\", \"1999\", \"2003\", \"1990\", \"1995\", \"1954\", \"1966\", \"1979\", \"1961\", \"1998\", \"1964\", \"1974\", \"2001\", \"1971\", \"1976\", \"1955\", \"1944\", \"1938\", \"1985\", \"1993\", \"1997\", \"2002\", \"1987\", \"1982\", \"1956\", \"2008\", \"1975\", \"1986\", \"1978\", \"1981\", \"1936\", \"1984\", \"1983\", \"2009\", \"2004\", \"2005\", \"1980\", \"1943\", \"2007\", \"1935\", \"2010\", \"1929\", \"2006\", \"1942\", \"1937\", \"2011\", \"1928\", \"1931\", \"1934\", \"1939\", \"1933\", \"1932\", \"1930\", \"1941\", \"2012\", \"1940\", \"2013\", \"2016\", \"2014\", \"1927\", \"2018\", \"2015\", \"1920\", \"2017\", \"1926\", \"1922\", \"1923\", \"2019\", \"1921\", \"1925\", \"2021\", \"1919\", \"2020\", \"1924\", \"1917\", \"2022\", \"1916\", \"1918\", \"1913\", \"1915\", \"2023\", \"1909\", \"1912\", \"1908\"])\n",
            "\n",
            "Constraint suggestion for 'Year': 'Year' has value range '1946', '1989', '1947', '1962', '1948', '1972', '1945', '1951', '1994', '1970', '1950', '1953', '1960', '1969', '1958', '1991', '1996', '1949', '1992', '1959', '1957', '1952', '1968', '1973', '1963', '1988', '1965', '2000', '1977', '1967', '1999', '2003', '1990', '1995', '1954', '1966', '1979', '1961', '1998', '1964', '1974', '2001', '1971', '1976', '1955', '1944', '1938', '1985', '1993', '1997', '2002', '1987', '1982', '1956', '2008', '1975', '1986', '1978', '1981', '1936', '1984', '1983', '2009', '2004', '2005', '1980', '1943', '2007', '1935', '2010', '1929', '2006', '1942', '1937', '2011', '1928', '1931', '1934', '1939' for at least 89.0% of values\n",
            "The corresponding Python code is: .isContainedIn(\"Year\", [\"1946\", \"1989\", \"1947\", \"1962\", \"1948\", \"1972\", \"1945\", \"1951\", \"1994\", \"1970\", \"1950\", \"1953\", \"1960\", \"1969\", \"1958\", \"1991\", \"1996\", \"1949\", \"1992\", \"1959\", \"1957\", \"1952\", \"1968\", \"1973\", \"1963\", \"1988\", \"1965\", \"2000\", \"1977\", \"1967\", \"1999\", \"2003\", \"1990\", \"1995\", \"1954\", \"1966\", \"1979\", \"1961\", \"1998\", \"1964\", \"1974\", \"2001\", \"1971\", \"1976\", \"1955\", \"1944\", \"1938\", \"1985\", \"1993\", \"1997\", \"2002\", \"1987\", \"1982\", \"1956\", \"2008\", \"1975\", \"1986\", \"1978\", \"1981\", \"1936\", \"1984\", \"1983\", \"2009\", \"2004\", \"2005\", \"1980\", \"1943\", \"2007\", \"1935\", \"2010\", \"1929\", \"2006\", \"1942\", \"1937\", \"2011\", \"1928\", \"1931\", \"1934\", \"1939\"], lambda x: x >= 0.89, \"It should be above 0.89!\")\n",
            "\n",
            "Constraint suggestion for 'Year': 'Year' has no negative values\n",
            "The corresponding Python code is: .isNonNegative(\"Year\")\n",
            "\n",
            "Constraint suggestion for 'Year': 'Year' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Year\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Day': 'Day' has value range '8', '15', '24', '27', '10', '14', '3', '2', '9', '21', '11', '22', '6', '12', '17', '18', '4', '20', '26', '29', '16', '19', '23', '28', '25', '13', '30', '5' for at least 90.0% of values\n",
            "The corresponding Python code is: .isContainedIn(\"Day\", [\"8\", \"15\", \"24\", \"27\", \"10\", \"14\", \"3\", \"2\", \"9\", \"21\", \"11\", \"22\", \"6\", \"12\", \"17\", \"18\", \"4\", \"20\", \"26\", \"29\", \"16\", \"19\", \"23\", \"28\", \"25\", \"13\", \"30\", \"5\"], lambda x: x >= 0.9, \"It should be above 0.9!\")\n",
            "\n",
            "Constraint suggestion for 'Day': 'Day' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Day\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Sum_of_Ground': 'Sum_of_Ground' has no negative values\n",
            "The corresponding Python code is: .isNonNegative(\"Sum_of_Ground\")\n",
            "\n",
            "Constraint suggestion for 'Sum_of_Ground': 'Sum_of_Ground' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Sum_of_Ground\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n",
            "Constraint suggestion for 'Country_Region': 'Country_Region' has less than 2% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Country_Region\", lambda x: x >= 0.98, \"It should be above 0.98!\")\n",
            "\n",
            "Constraint suggestion for 'Date': 'Date' is not null\n",
            "The corresponding Python code is: .isComplete(\"Date\")\n",
            "\n",
            "Constraint suggestion for 'Date': 'Date' is unique\n",
            "The corresponding Python code is: .isUnique(\"Date\")\n",
            "\n",
            "Constraint suggestion for 'Aircraft': 'Aircraft' has less than 1% missing values\n",
            "The corresponding Python code is: .hasCompleteness(\"Aircraft\", lambda x: x >= 0.99, \"It should be above 0.99!\")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics Repository**"
      ],
      "metadata": {
        "id": "jvGyri4z72_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.repository import FileSystemMetricsRepository, ResultKey\n",
        "from pydeequ.analyzers import AnalysisRunner, ApproxCountDistinct\n",
        "\n",
        "metrics_file = FileSystemMetricsRepository.helper_metrics_file(spark, 'metrics.json')\n",
        "repository = FileSystemMetricsRepository(spark, metrics_file)"
      ],
      "metadata": {
        "id": "_nq13K5076pg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tag for the result key\n",
        "key_tags = {'tag': 'AirCrashAnalysis'}\n",
        "resultKey = ResultKey(spark, ResultKey.current_milli_time(), key_tags)\n",
        "\n",
        "# Run the analysis\n",
        "analysisResult = AnalysisRunner(spark) \\\n",
        "                         .onData(df) \\\n",
        "                         .addAnalyzer(ApproxCountDistinct('Year')) \\\n",
        "                         .useRepository(repository) \\\n",
        "                         .saveOrAppendResult(resultKey) \\\n",
        "                         .run()"
      ],
      "metadata": {
        "id": "vHswW9ZP785g"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysisResult_metrics_repository = repository.load() \\\n",
        "                           .before(ResultKey.current_milli_time()) \\\n",
        "                           .getSuccessMetricsAsDataFrame()\n",
        "analysisResult_metrics_repository.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJdiCjeG7_LO",
        "outputId": "7229b6f6-4168-4cec-e019-06a4664ccc00"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------------------+-----+-------------+----------------+\n",
            "|entity|instance|               name|value| dataset_date|             tag|\n",
            "+------+--------+-------------------+-----+-------------+----------------+\n",
            "|Column|    Year|ApproxCountDistinct|113.0|1695001177325|AirCrashAnalysis|\n",
            "+------+--------+-------------------+-----+-------------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}